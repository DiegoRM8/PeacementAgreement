---
title: "Untitled"
author: "Diego Refoyo Matellán"
date: "24/5/2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PEC1-header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Detalles de la actividad

## Descripción de la actividad

A lo largo de esta actividad, se desarrolllará un caso práctico, cuyo objetivo principal es el tratamiento de un conjunto de datos o dataset, orientado a aprender a identificar los datos relevantes para unproyecto analítico. Además de hacer uso de las herramientas de integración, limpieza, validación y análisis de las mismas.

## Objetivos

Los objetivos que se buscar lograr en esta actividad práctica son los
siguientes:

- Aplicar los conocimientos adquiridos y su capacidad de resolución de
problemas en nuevos entornos o poco conocidos dentro de contextos más amplios o
multidisciplinares.

- Identificar los datos relevantes y los tratamientos necesarios (integración, limpieza
y validación) para llevar a cabo un proyecto analítico.

- Analizar los datos adecuadamente para abordar la información contenida en
los datos.

- Identificar la mejor forma de representar los resultados obtenidos, de manera que permitan extraer conclusiones de la manera más sencila posible sobre el problema planteado en el proceso analítico.

- Actuar con los principios éticos y legales relacionados con la manipulación de datos en
función del ámbito de aplicación.

- Desarrollar las habilidades de aprendizaje que permita continuar estudiando de un
modo que tendrá que ser en gran medida autodirigido o autónomo.

- Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el
ámbito de la ciencia de datos.

## Competencias

Así, las competencias del Máster en Data Science que se desarrollan son:

- Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

- Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.

# Resolución

## Descripción del dataset

El conjunto de datos elegido ha sido 'Red Wine Quality', el cual se ha descargado de la página kaggle (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009). Dicho conjunto de datos consta de 12 variables y 1600 registros.

Las variables contenidas en el dataset son las siguientes:

1 fixed acidity: se refiere a la acidez fija del vino.

2 - volatile acidity: la cantidad de ácido acético en el vino, que en niveles demasiado altos puede provocar un sabor desagradable a vinagre

3 - citric acid: se encuentra en pequeñas cantidades, el ácido cítrico puede agregar 'frescura' y sabor a los vinos

4 - residual sugar: la cantidad de azúcar que queda después de que se detiene la fermentación, es raro encontrar vinos con menos de 1 gramo / litro y los vinos con más de 45 gramos / litro se consideran dulces

5 - chlorides: la cantidad de sal en el vino

6 - free sulfur dioxide: la forma libre de SO2 existe en equilibrio entre el SO2 molecular (como gas disuelto) y el ion bisulfito; Previene el crecimiento microbiano y la oxidación del vino.

7 - total sulfur dioxide: cantidad de formas libres y ligadas de SO2; en bajas concentraciones, el SO2 es mayormente indetectable en el vino, pero en concentraciones de SO2 libre superiores a 50 ppm, el SO2 se hace evidente en la nariz y el sabor del vino.

8 - density: la densidad del agua es cercana a la del agua dependiendo del porcentaje de alcohol y contenido de azúcar

9 - pH: describe qué tan ácido o básico es un vino en una escala de 0 (muy ácido) a 14 (muy básico); la mayoría de los vinos están entre 3-4 en la escala de pH

10 -  sulphates: aditivo del vino que puede contribuir a los niveles de dióxido de azufre (SO2), que actúa como antimicrobiano y antioxidante.

11 - alcohol: el porcentaje de contenido de alcohol del vino

Variable de salida (basada en datos sensoriales): 12 - quality (puntuación entre 0 y 10)

## Importancia y objetivos de los análisis

## Limpieza de los datos

En primer lugar, antes de comenzar con la limpieza de datos, se cargará el dataset que se va a utilizar. Para ello, se utilizará la función read.cv(), que permite leer archivos de tipo .cvs conviertiéndolos en un objeto de tipo dataframe.

```{r}
library(kableExtra) # biblioteca empleada para mejorar la estética de las tablas
library(scales) # biblioteca necesaria para escalar las variables
library(nortest) # biblioteca necesaria para realizar pruebas de normalidad
```


```{r}

# Lectura del archivo

dataframe <- read.csv("C:/Users/USUARIO/Desktop/Master/Segundo_Cuatri/Tipología y ciclo/PRAC1/winequality-red.csv")

```

Una vez cargados los datos, se muestran en una tabla para poder ir conociéndolos mejor. Además, en la tabla que se muestra a continuación, se puede observar el tipo de variable del que se trata en cada ocasión.

```{r}

rmarkdown::paged_table(dataframe)

```

Como se puede observar, todas las variables son numéricas. Por lo tanto, se mostrará un resumen que arroje más luz sobre las características de cada una de las variables.

```{r}
summary(dataframe)%>%
  kable()%>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")
```

### Selección de datos de interés

En esta ocasión, se ha decido trabajar con todas las columnas debido, principalmente, a que no se trata de un número muy elevado de variables, y a que todas parecen aportar información relevante.

Es posible que a la hora de aplicar algún algoritmo sobre el conjunto de datos, alguna de las variables sea tratada para ese caso en concreto. Por ejemplo, convertir la variable target "quality" en una variable binaria, donde el 1 represente valores de calidad altos (> 7) y cero valores de calidad bajos (<= 7). Sin embargo, esto será tratado más adelante.


### Búsqueda de valores desconocidos 

El primer paso en la limpieza de datos consistirá en realizar una búsqueda de valores perdidos, es decir, saber si existen observaciones para las cuales no se conoce su valor. Para ello, se utilizará la función propia de R "is.na()". Recordar, que este es un paso muy importante, ya que algunas funciones de R podrían no funcionar de manera correcta en caso de haber valores nulos.

En el caso de encontrar valores Nan, habrá que decidir qué hacer con ellos. En el caso más trivial, siempre y cuando no representen un porcentaje elevado de observaciones, se podría optar por eliminar las filas en la que haya valores desconocidos. Sin embargo, en el caso de no considerar esto una buena práctica, existen otros métodos como sustituirlos por la media o la mediana de la variable a la que correspondan. En el caso, de elegir sustituir por la media de la variable, hay que prestar especial atención a que dicha variable no contenga valores extremos, ya que la media es un estadístico muy sensiblea este tipo de valores.

```{r}

colSums(is.na(dataframe))%>% #Se analiza el número de Na que hay en cada variable
  kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")
```

Como se puede observar en la tabla anterior, en un primer momento, parece que no hay ningún valor perdido. Sin embargo, conviene realizar un estudio un poco más profundo, ya que en muchas situaciones, los valores desconocidos se codifican de otra forma distinta. Por ejemplo, "Na", "NAN", "?", etc.

En esta ocasión, se realizará un ejemplo de cómo sería la búsqueda de estos valores. Sin embargo, no se esperá encontrar otra codificación para los valores nulos ya que en caso de ser así, la variable sería categorizada por R como caracter y, tal y como se ha visto antes, todas las variables se consideran numéricas.

Para buscar otra codificación de los valores perdidos, basta con modificar un poco la sentencia anterior.

```{r}

colSums(dataframe=="?") %>%
   kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")

```

Tal y como se esperaba, no existe ningún valor desconocido codificado como "?". Para estudiar otro tipo de codificaciones, bastaría con sustituit "?" por el valor deseado.


### Tratamiento de valores extremos

Como ya se comentó anteriormente de pasada, además de valores desconocidos, también pueden existir valores extremos que alteren los resultados obtenidos al realizar análisis estadísticos sobre el conjunto de datos.

En un primer momento, habrá que detectar aquellos valores extremos o *outliers* para, posteriormente, decidir si son valores extremos pero razonables o si se deben a una mala codificación a la hora de introducir los datos. En este último caso, habría que decidir qué hacer con ellos.

```{r}

boxplot.stats(dataframe$fixed.acidity)$out

```
```{r}

boxplot.stats(dataframe$volatile.acidity)$out

```

```{r}

boxplot.stats(dataframe$citric.acid)$out

```

```{r}

boxplot.stats(dataframe$residual.sugar)$out

```

```{r}

boxplot.stats(dataframe$chlorides)$out

```

```{r}

boxplot.stats(dataframe$free.sulfur.dioxide)$out

```

```{r}

boxplot.stats(dataframe$total.sulfur.dioxide)$out

```

```{r}

boxplot.stats(dataframe$density)$out

```

```{r}

boxplot.stats(dataframe$pH)$out

```

```{r}

boxplot.stats(dataframe$sulphates)$out

```

```{r}

boxplot.stats(dataframe$alcohol)$out

```
```{r}

boxplot.stats(dataframe$quality)$out

```

Como se puede observar en las salidas por pantalla de cada variable, en todas ellas existen valores extremos. Sin emargo, en ninuguna se ha detectado un caso anómalo que no pueda darse. Por ejemplo, respecto al alcohol, los valores extremos se deben a que los vinos a los que corresponden tienen una cantidad de alcohol alta para ser un vino. Pero, a pesar de ello, son valores razonables que pueden existir. Algo extraño, sería un valor de 60, más propio de una bebida alcohólica destilada que de un vino.

Por lo tanto, se ha tomado la decisión de seguir trabajando con dichos valores sin modificarlos.

### Reescalar variables

Con el fin de evitar posibles problemas al realizar los posteriores análisis estadísticos, se ha decididido reescalar las variables mediante el método minmax para que todas ellas se encuentren en el mismo intevalos de valores. De esta forma, los resultados obtenidos en los análisis serán más fiables.

El reescalado se llevará a cabo con el paquete de R *scales* que, por defecto, emplea la siguiente fórmula: 
  
  $x_{escalada} = \frac{x - min(x)}{max(x) - min(x)}$ 

```{r}

dataframe$fixed.acidity_escalado <- rescale(dataframe$fixed.acidity)
dataframe$volatile.acidity_escalado <- rescale(dataframe$volatile.acidity)
dataframe$citric.acid_escalado <- rescale(dataframe$citric.acid)
dataframe$residual.sugar_escalado <- rescale(dataframe$residual.sugar)
dataframe$chlorides_escalado <- rescale(dataframe$chlorides)
dataframe$free.sulfur.dioxide_escalado <- rescale(dataframe$free.sulfur.dioxide)
dataframe$total.sulfur.dioxide_escalado <- rescale(dataframe$total.sulfur.dioxide)
dataframe$density_escalado <- rescale(dataframe$density)
dataframe$pH_escalado <- rescale(dataframe$pH)
dataframe$sulphates_escalado <- rescale(dataframe$sulphates)
dataframe$alcohol_escalado <- rescale(dataframe$alcohol)
dataframe$quality_escalado <- rescale(dataframe$quality)
  

```

Una vez que se han reescalado las variables se crea un nuevo dataframe y se muestra un resumen de este, en el que se puede comprobar que todas se encuentran en la misma escala.

```{r}

dataframe_escalado <- dataframe[13:24] #se seleccionan solo las variables escaladas

rmarkdown::paged_table(dataframe_escalado)

summary(dataframe_escalado) %>%
   kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")

```


### Exportación de los datos preprocesados

Una vez que hemos acometido sobre el conjunto de datos inicial los procedimientos de
integración, validación y limpieza anteriores, procedemos a guardar estos en un nuevo fichero denominado winequality-red_clean.csv.

```{r}

write.csv(dataframe_escalado, "C:\\Users\\USUARIO\\Desktop\\Master\\Segundo_Cuatri\\Tipología y ciclo\\PRAC1\\winequality-red_clean.csv")

```


## Análisis de los datos

### Selección de los grupos de interés

A continuación, se seleccionan los grupos dentro de nuestro conjunto de datos que pueden
resultar interesantes para analizar y/o comparar. No obstante, como se verá en el apartado
consistente en la realización de pruebas estadísticas, no todos se utilizarán.

Para ello, habrá que recodificar ciertas variables y convertirlas a culitativas. Esto se realizará para las siguientes variables: pH, alcohol y quality. En cada caso, se seguirá un criterio a la hora de recodificarlas.

#### pH

Atendiendo a la definición de pH y la forma en la que se distingue en grupos en el ámbito científico, se clasificará como *ácido* aquellos valores de la variable pH < 0.5, como *neutro* para pH = 0.5 y *alcalino* para pH > 0.5.

```{r}

for(i in 1:dim(dataframe_escalado)[1]){
  
  if(dataframe_escalado$pH_escalado[i] > 0.5) dataframe_escalado$pH_rec[i] <- "alcalino"
  else if (dataframe_escalado$pH_escalado[i] < 0.5) dataframe_escalado$pH_rec[i] <- "acido"
  else dataframe_escalado$pH_rec[i] <- "neutro"
  
}

```

Se muestra la nueva variable para comprobar que la recodificación ha sido exitosa.

```{r}
head(dataframe_escalado["pH_rec"],5)%>%
   kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")

```

Para las otras dos variables, se seguirá el mismo criterio en la recodificación. Se considerará un valor alto cuando la puntuación sea > 0.7 y bajo en el resto de los casos.

```{r}

for(i in 1:dim(dataframe_escalado)[1]){
  
  if(dataframe_escalado$alcohol_escalado[i] > 0.7) dataframe_escalado$alcohol_rec[i] <- "alto"
  else dataframe_escalado$alcohol_rec[i] <- "bajo"
  
  
  if(dataframe_escalado$quality_escalado[i] > 0.7) dataframe_escalado$quality_rec[i] <- "alto"
  else dataframe_escalado$quality_rec[i] <- "bajo"
  
}


```

Se muestran las nuevas variables obtenidas:

```{r}
head(dataframe_escalado["alcohol_rec"],5)%>%
   kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")

```

```{r}
head(dataframe_escalado["quality_rec"],5)%>%
   kbl() %>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")

```

Ahora sí, se pueden definir los grupos de interés:

```{r}

# Agrupación por tipo de pH

ph_acido <- dataframe_escalado[dataframe_escalado$pH_rec == "acido", ]
ph_neutro <- dataframe_escalado[dataframe_escalado$pH_rec == "neutro", ]
ph_alcalino <- dataframe_escalado[dataframe_escalado$pH_rec == "alcalino", ]

# Agrupación por cantidad de alcohol

alcohol_alto <- dataframe_escalado[dataframe_escalado$alcohol_rec == "alto", ]
alcohol_bajo <- dataframe_escalado[dataframe_escalado$alcohol_rec == "bajo", ]

#Agrupación por calidad
quality_alto <- dataframe_escalado[dataframe_escalado$quality_rec == "alto", ]
quality_bajo <- dataframe_escalado[dataframe_escalado$quality_rec == "bajo", ]
```


### Comprobación de la normalidad y homogeneidad de la varianza

Para tener una primera impresión o idea acerca de si las variables que contiene el conjunto de datos sigue una distribución normal, se puede realizar una representación gráfica mediante un histograma. A continuación, se muestra el histograma de alguna de las variables del dataset.


```{r}

hist(x = dataframe_escalado$alcohol_escalado, main = "Distribución de la variable Alcohol", 
     xlab = "Volumen de Alcohol", ylab = "Frecuencia",
     col = "blue")

```

Como se puede observar en el gráfico anterior, la variable *Alcohol* no parece seguir una distribución normal.

```{r}

hist(x = dataframe_escalado$pH_escalado, main = "Distribución de la variable pH", 
     xlab = "pH", ylab = "Frecuencia",
     col = "blue")

```

Como se puede observar en el gráfico anterior, la variable *pH* podría seguir una distribución normal.

```{r}

hist(x = dataframe_escalado$quality_escalado, main = "Distribución de la variable Quallity", 
     xlab = "Quality", ylab = "Frecuencia",
     col = "blue")

```

Como se puede observar en el gráfico anterior, la variable *Quality* no parece seguir una distribución normal.

Sin embargo, los gráficos solo permiten tener una primera impresión. Para poder afirmar si una variable sigue o no una distribución normal, hay que realizar una prueba estadística.

En esta ocasión, para la comprobación de que los valores que toman las variables cuantitativas provienen de una población distribuida normalmente, se utilizará la prueba de normalidad de AndersonDarling.

Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de
significación prefijado α = 0, 05. Si esto se cumple, entonces se considera que variable en cuestión sigue una distribución normal.

```{r}

alpha = 0.05
col.names = colnames(dataframe_escalado)

for (i in 1:ncol(dataframe_escalado)) {

    if (i == 1) cat("Las variables que no siguen una distribución normal son las siguientes:\n")
    
    if (is.integer(dataframe_escalado[,i]) | is.numeric(dataframe_escalado[,i])) {
    
        p_val = ad.test(dataframe_escalado[,i])$p.value

        if (p_val < alpha) {
  
          cat(col.names[i])
          # Format output
          if (i < ncol(dataframe_escalado) - 1) cat(", ")

          if (i %% 3 == 0) cat("\n")
        }
    }
}

```

Tras obtener los resultados del test Anderson Darling, se puede concluir que ninguna de las variables del dataset con el que se está trabajando sigue una distribución normal. 

Otro estudio interesante es el de la homogeneidad de la varianza. Para saber si hay homocedasticidad en las variables del dataset, se utilizará el test de Fligner-Killeen ya que ninguna de las variables sigue una distribución normal.

En particular, se estudiará si existe homocedasticidad entre la calidad del vino entre los que tienen un volumen de alcohol alto y bajo.

Las hipótesis que establece el test son las siguientes:

  - $H_{0}$: Existe  homocedasticidad entre las variables
  
  - $H_{1}$: No existe homocedasticidad entre las variables
  

```{r}

alto <- dataframe_escalado[dataframe_escalado$alcohol_rec == 'alto', "quality_escalado"]

bajo <- dataframe_escalado[dataframe_escalado$alcohol_rec == 'bajo', "quality_escalado"]

fligner.test(x = list(alto,bajo))
```

Como el p.valor obtenido es < 0.05, existen evidencias suficientes para rechazar la hipótesis nula que establecía homocedasticidad entre las variables estudiadas. Es decir, que tienen varianzas diferentes.


## Pruebas estadísticas

### ¿Qué variables cuantitativas influyen más en la calidad del vino?


En primer lugar, se realizará un análisis de correlación entre las distintas variables para determinar cuáles de ellas ejercen una mayor influencia sobre la calidad del vino. Para ello, se utilizará el coeficiente de correlación de Spearman, puesto que se ha visto que las variables no siguen una distribución normal.

```{r, warning=FALSE, message=FALSE}

corr_matrix <- matrix(nc = 2, nr = 0)

colnames(corr_matrix) <- c("estimate", "p-value")

# Calcular el coeficiente de correlación para cada variable cuantitativa
# con respecto al campo "precio"

for (i in 1:(ncol(dataframe_escalado) - 1)) {

  if (is.integer(dataframe_escalado[,i]) | is.numeric(dataframe_escalado[,i])) {

    spearman_test = cor.test(dataframe_escalado[,i],
                    dataframe_escalado[,12],
                    method = "spearman")

    corr_coef = spearman_test$estimate

    p_val = spearman_test$p.value

    # Add row to matrix

    pair = matrix(ncol = 2, nrow = 1)

    pair[1][1] = corr_coef

    pair[2][1] = p_val

    corr_matrix <- rbind(corr_matrix, pair)

    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(dataframe_escalado)[i]
}
}


```


```{r}
corr_matrix %>%
  kable()%>%
  kable_styling()%>%
  row_spec(row = 0, bold = T, color = "white", background = "#BE8F00")
```

En un primer momento, parece que ninguna variable del dataset se encuentra directamente correlacionada con la variable *quality*, ya que los valores obtenidos son lejanos de 1 ó -1(con la salvedad de la propia variable con ella misma).

Sin embargo, podría darse el caso de que al analizar la dependencia entre más de una variables del dataset con la variable target, cambiaran los resultados.
